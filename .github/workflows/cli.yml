name: CLI weekly live test

on:
  schedule:
    - cron: "0 18 * * 0"
  workflow_dispatch:
    inputs:
      test-cases:
        description: 'Specific test cases to run. Example: ["test_integration_create_aws", "test_integration_delete"]. Leave empty to run all test cases'
        required: false
        type: string

permissions:
  id-token: write
  contents: read

jobs:
  setup:
    runs-on: ubuntu-latest
    environment: engineering
    outputs:
      chunk-matrix: ${{ steps.create-matrix.outputs.chunk-matrix }}
      python-versions: ${{ steps.create-matrix.outputs.python-versions }}
      test-cases: ${{ steps.create-matrix.outputs.test-cases }}
      total-chunks: ${{ steps.create-matrix.outputs.total-chunks }}
    steps:
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: "3.11"

      - name: Azure login
        uses: azure/login@v2
        with:
          client-id: ${{secrets.APICEXT_TEST_AZURE_CLIENT_ID}}
          tenant-id: ${{secrets.APICEXT_TEST_AZURE_TENANT_ID}}
          subscription-id: ${{secrets.APICEXT_TEST_AZURE_SUBSCRIPTION_ID}}
          enable-AzPSSession: true

      - name: Clone azure-cli-extensions repository
        run: |
          git clone https://github.com/blackchoey/azure-cli-extensions.git
          cd azure-cli-extensions
          git checkout main

      - name: Setup development environment
        run: |
          cd azure-cli-extensions
          python -m venv .venv
          source .venv/bin/activate
          python -m pip install -U pip
          pip install azdev
          azdev setup -r .
          azdev extension add apic-extension

      - name: Create intelligent matrix configuration
        id: create-matrix
        run: |
          # Check if specific test cases are provided via workflow_dispatch
          inputCases='${{ github.event.inputs.test-cases }}'
          if [ -n "$inputCases" ] && [ "$inputCases" != "null" ]; then
            echo "Using manually specified test cases: $inputCases"
            test_cases="$inputCases"
            total_tests=$(echo "$test_cases" | jq '. | length')
          else
            # Automatically discover test cases using pytest --collect-only
            cd azure-cli-extensions
            source .venv/bin/activate
            cd src/apic-extension

            echo "Discovering test cases using pytest --collect-only..."
            test_collection_output=$(python -m pytest --collect-only -q 2>/dev/null || true)

            # Extract test function names from pytest collection output
            if echo "$test_collection_output" | grep -q "<TestCaseFunction"; then
              test_collection=$(echo "$test_collection_output" | grep -E "^\s*<TestCaseFunction" | sed -E 's/.*<TestCaseFunction ([^>]+)>.*/\1/' | sort | uniq)
            elif echo "$test_collection_output" | grep -q "::test_"; then
              test_collection=$(echo "$test_collection_output" | grep -E "::test_" | sed -E 's/.*::([^:]+)$/\1/' | sort | uniq)
            else
              test_collection=""
            fi

            if [ -n "$test_collection" ]; then
              test_count=$(echo "$test_collection" | wc -l)
              echo "Discovered $test_count test cases"
              test_cases=$(echo "$test_collection" | jq -R -s -c 'split("\n") | map(select(length > 0))')
              total_tests=$(echo "$test_cases" | jq '. | length')
              echo "Found $total_tests test cases total"
            else
              echo "No test cases found, using full-suite approach"
              test_cases='["full-suite"]'
              total_tests=1
            fi
          fi

          # Store test cases for notify job
          echo "test-cases=$test_cases" >> $GITHUB_OUTPUT

          # Create chunked test groups to stay within GitHub's 256 matrix limit
          python_versions='["3.9", "3.10", "3.11", "3.12"]'
          max_tests_per_chunk=60  # 60 tests × 4 python versions = 240 matrix combinations (under 256 limit)

          # Calculate chunks
          if [ "$total_tests" -le "$max_tests_per_chunk" ]; then
            # All tests fit in one chunk
            echo "All $total_tests tests fit in one chunk"
            total_chunks=1
            chunk_matrix=$(jq -n --argjson tests "$test_cases" '[{chunk_id: 0, test_cases: $tests}]')
          else
            # Split into multiple chunks
            total_chunks=$(( (total_tests + max_tests_per_chunk - 1) / max_tests_per_chunk ))
            echo "Splitting $total_tests tests into $total_chunks chunks of up to $max_tests_per_chunk tests each"

            chunk_matrix=$(echo "$test_cases" | jq --argjson chunk_size "$max_tests_per_chunk" '
              [range(0; length; $chunk_size) as $i | {
                chunk_id: ($i / $chunk_size | floor),
                test_cases: .[$i:$i+$chunk_size]
              }]
            ')
          fi

          echo "chunk-matrix=$(echo "$chunk_matrix" | jq -c '.')" >> $GITHUB_OUTPUT
          echo "python-versions=$python_versions" >> $GITHUB_OUTPUT
          echo "total-chunks=$total_chunks" >> $GITHUB_OUTPUT

          # Debug output
          echo "DEBUG: Created $total_chunks chunks:"
          echo "$chunk_matrix" | jq -r '.[] | "  Chunk \(.chunk_id): \(.test_cases | length) test cases"'
          echo "DEBUG: First chunk test cases preview:"
          echo "$chunk_matrix" | jq -r '.[0].test_cases[:3][] // empty'

  execute-tests:
    needs: setup
    runs-on: ubuntu-latest
    environment: engineering
    strategy:
      fail-fast: false
      matrix:
        chunk: ${{ fromJson(needs.setup.outputs.chunk-matrix) }}
        python-version: ${{ fromJson(needs.setup.outputs.python-versions) }}
    name: Chunk ${{ matrix.chunk.chunk_id }} (Python ${{ matrix.python-version }})
    steps:
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: ${{ matrix.python-version }}

      - name: Azure login
        uses: azure/login@v2
        with:
          client-id: ${{ secrets.APICEXT_TEST_AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.APICEXT_TEST_AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.APICEXT_TEST_AZURE_SUBSCRIPTION_ID }}
          enable-AzPSSession: true

      - name: Clone azure-cli-extensions repository
        run: |
          git clone https://github.com/blackchoey/azure-cli-extensions.git
          cd azure-cli-extensions
          git checkout main

      - name: Setup development environment
        run: |
          cd azure-cli-extensions
          python -m venv .venv
          source .venv/bin/activate
          python -m pip install -U pip
          pip install azdev
          azdev setup -r .
          azdev extension add apic-extension

      - name: Execute test cases for chunk
        run: |
          # Get the test cases for this chunk
          test_cases='${{ toJson(matrix.chunk.test_cases) }}'
          chunk_id='${{ matrix.chunk.chunk_id }}'
          python_version='${{ matrix.python-version }}'

          echo "Running chunk $chunk_id test cases (Python $python_version)"
          echo "Test cases: $test_cases"

          cd azure-cli-extensions
          source .venv/bin/activate

          # Initialize result tracking
          passed_tests=""
          failed_tests=""
          total_tests=0
          passed_count=0
          failed_count=0

          # Parse test cases JSON array into bash array to avoid subshell variable scope issues
          mapfile -t test_case_array < <(echo "$test_cases" | jq -r '.[]')


          # Run each test case
          for test_case in "${test_case_array[@]}"; do
            echo "=========================================="
            echo "Running: $test_case (Python $python_version)"
            echo "=========================================="

            total_tests=$((total_tests + 1))
            test_passed=false
            max_retries=5

            # Run the specific test case with retry logic
            for attempt in $(seq 1 $max_retries); do
              echo "Attempt $attempt/$max_retries for $test_case"

              if [ "$test_case" = "full-suite" ]; then
                echo "Running full test suite..."
                if azdev test apic-extension --discover --live; then
                  test_passed=true
                  break
                fi
              else
                echo "Running individual test case: $test_case"
                if azdev test azext_apic-extension $test_case --discover --live; then
                  test_passed=true
                  break
                fi
              fi

              if [ $attempt -lt $max_retries ]; then
                echo "❌ Attempt $attempt failed, retrying in 10 seconds..."
                sleep 10
              fi
            done

            # Record final result
            if [ "$test_passed" = true ]; then
              echo "✅ PASSED: $test_case (Python $python_version)"
              passed_count=$((passed_count + 1))
              if [ -z "$passed_tests" ]; then
                passed_tests="$test_case"
              else
                passed_tests="$passed_tests,$test_case"
              fi
            else
              echo "❌ FAILED: $test_case (Python $python_version) after $max_retries attempts"
              failed_count=$((failed_count + 1))
              if [ -z "$failed_tests" ]; then
                failed_tests="$test_case"
              else
                failed_tests="$failed_tests,$test_case"
              fi
            fi

            echo "Completed: $test_case (Python $python_version)"
            echo ""
          done

          # Output summary for this chunk
          echo "=========================================="
          echo "CHUNK $chunk_id (Python $python_version) SUMMARY:"
          echo "Total: $total_tests, Passed: $passed_count, Failed: $failed_count"
          if [ -n "$passed_tests" ]; then
            echo "Passed tests: $passed_tests"
          fi
          if [ -n "$failed_tests" ]; then
            echo "Failed tests: $failed_tests"
          fi
          echo "=========================================="

          # Fail the job if any test failed (preserve original behavior)
          if [ $failed_count -gt 0 ]; then
            echo "Job failed because $failed_count test(s) failed"
            exit 1
          fi
        env:
          USERASSIGNED_IDENTITY: ${{ secrets.USERASSIGNED_IDENTITY }}
          AWS_ACCESS_KEY_LINK: ${{ secrets.AWS_ACCESS_KEY_LINK }}
          AWS_SECRET_ACCESS_KEY_LINK: ${{ secrets.AWS_SECRET_ACCESS_KEY_LINK }}
  notify:
    needs: [setup, execute-tests]
    if: (github.event_name == 'schedule' || github.event_name == 'workflow_dispatch') && !cancelled()
    runs-on: ubuntu-latest
    environment: engineering
    steps:
      - name: Generate Email Content
        id: generate-email-content
        run: |
          # Get the test cases that were executed
          test_cases='${{ needs.setup.outputs.test-cases }}'
          total_chunks='${{ needs.setup.outputs.total-chunks }}'

          # Initialize counters
          total_test_cases=0
          passed_test_cases=0
          failed_test_cases=0

          # Initialize temporary files for collecting results
          mkdir -p /tmp/test_results
          > /tmp/test_results/passed.txt
          > /tmp/test_results/failed.txt

          echo "Analyzing test results for notification..."

          # Fetch all jobs from the workflow run
          jobs_response=$(curl -s -H "Accept: application/vnd.github.v3+json" \
            -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
            "https://api.github.com/repos/${{ github.repository }}/actions/runs/${{ github.run_id }}/jobs")

          python_versions=("3.9" "3.10" "3.11" "3.12")

          # Process each job to extract individual test results
          for python_version in "${python_versions[@]}"; do
            for chunk_id in $(seq 0 $((total_chunks - 1))); do
              job_name="Chunk ${chunk_id} (Python ${python_version})"
              echo "Processing job: $job_name"

              job_info=$(echo "$jobs_response" | jq -r --arg name "$job_name" '.jobs[] | select(.name == $name) | {id: .id, conclusion: .conclusion}')

              if [ "$job_info" != "null" ] && [ -n "$job_info" ]; then
                job_id=$(echo "$job_info" | jq -r '.id')
                job_conclusion=$(echo "$job_info" | jq -r '.conclusion')

                if [ "$job_id" != "null" ] && [ -n "$job_id" ]; then
                  echo "  Fetching logs for job ID: $job_id"
                  # Get job logs
                  job_logs=$(curl -s -L -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
                    "https://api.github.com/repos/${{ github.repository }}/actions/jobs/$job_id/logs" 2>/dev/null || echo "")
                  if [ -n "$job_logs" ]; then
                    echo "    Processing job logs for Python $python_version, chunk $chunk_id..."

                    # Extract passed tests - write directly to avoid subshell issues
                    echo "$job_logs" | grep -E "✅ PASSED:" | sed -E 's/.*✅ PASSED: ([a-zA-Z0-9_][a-zA-Z0-9_.-]*).*/\1/' | \
                      grep -E '^[a-zA-Z0-9_][a-zA-Z0-9_.-]*$' | sort -u > /tmp/temp_passed_${python_version}_${chunk_id}.txt

                    # Debug: Show what we extracted
                    temp_passed_count=$(wc -l < /tmp/temp_passed_${python_version}_${chunk_id}.txt 2>/dev/null || echo "0")
                    echo "    Found $temp_passed_count passed tests in logs"
                    if [ "$temp_passed_count" -gt 0 ]; then
                      echo "    Sample passed tests:"
                      head -3 /tmp/temp_passed_${python_version}_${chunk_id}.txt
                    fi

                    # Add Python version suffix to each test name
                    if [ -f "/tmp/temp_passed_${python_version}_${chunk_id}.txt" ]; then
                      while IFS= read -r test_name; do
                        if [ -n "$test_name" ]; then
                          echo "${test_name} (Python ${python_version})" >> /tmp/test_results/passed.txt
                        fi
                      done < /tmp/temp_passed_${python_version}_${chunk_id}.txt
                      rm -f "/tmp/temp_passed_${python_version}_${chunk_id}.txt"
                    fi

                    # Extract failed tests - write directly to avoid subshell issues
                    echo "$job_logs" | grep -E "❌ FAILED:" | sed -E 's/.*❌ FAILED: ([a-zA-Z0-9_][a-zA-Z0-9_.-]*).*/\1/' | \
                      grep -E '^[a-zA-Z0-9_][a-zA-Z0-9_.-]*$' | sort -u > /tmp/temp_failed_${python_version}_${chunk_id}.txt

                    # Debug: Show what we extracted
                    temp_failed_count=$(wc -l < /tmp/temp_failed_${python_version}_${chunk_id}.txt 2>/dev/null || echo "0")
                    echo "    Found $temp_failed_count failed tests in logs"
                    if [ "$temp_failed_count" -gt 0 ]; then
                      echo "    Sample failed tests:"
                      head -3 /tmp/temp_failed_${python_version}_${chunk_id}.txt
                    fi

                    # Add Python version suffix to each test name
                    if [ -f "/tmp/temp_failed_${python_version}_${chunk_id}.txt" ]; then
                      while IFS= read -r test_name; do
                        if [ -n "$test_name" ]; then
                          echo "${test_name} (Python ${python_version})" >> /tmp/test_results/failed.txt
                        fi
                      done < /tmp/temp_failed_${python_version}_${chunk_id}.txt
                      rm -f "/tmp/temp_failed_${python_version}_${chunk_id}.txt"
                    fi
                  else
                    echo "  No logs available, using job conclusion: $job_conclusion"
                    # Fallback: Use job-level results if logs aren't available
                    if [ "$job_conclusion" = "success" ]; then
                      echo "$job_name (logs unavailable)" >> /tmp/test_results/passed.txt
                    else
                      echo "$job_name (logs unavailable)" >> /tmp/test_results/failed.txt
                    fi
                  fi
                fi
              fi
            done
          done

          # Count results from files
          passed_test_cases=$(wc -l < /tmp/test_results/passed.txt || echo "0")
          failed_test_cases=$(wc -l < /tmp/test_results/failed.txt || echo "0")
          total_test_cases=$((passed_test_cases + failed_test_cases))

          echo "Test results summary:"
          echo "  Total: $total_test_cases"
          echo "  Passed: $passed_test_cases"
          echo "  Failed: $failed_test_cases"          # Debug: Show what's actually in the result files
          echo "=== Debug: Content of result files ==="
          echo "Passed tests file size: $(wc -l < /tmp/test_results/passed.txt 2>/dev/null || echo '0') lines"
          echo "Failed tests file size: $(wc -l < /tmp/test_results/failed.txt 2>/dev/null || echo '0') lines"
          echo "Passed tests (first 10 lines):"
          if [ -f "/tmp/test_results/passed.txt" ]; then
            head -10 /tmp/test_results/passed.txt
          else
            echo "No passed.txt file"
          fi
          echo "Failed tests (first 10 lines):"
          if [ -f "/tmp/test_results/failed.txt" ]; then
            head -10 /tmp/test_results/failed.txt
          else
            echo "No failed.txt file"
          fi
          echo "=== End Debug ==="

          # Calculate per-Python version statistics
          mkdir -p /tmp/version_stats
          for python_version in "${python_versions[@]}"; do
            echo "Processing statistics for Python $python_version..."

            # Try different grep patterns to see what works
            echo "  Searching for pattern: 'Python ${python_version}'"
            echo "  Trying exact pattern match..."
            passed_count=$(grep -c "Python ${python_version}" /tmp/test_results/passed.txt 2>/dev/null || echo "0")
            failed_count=$(grep -c "Python ${python_version}" /tmp/test_results/failed.txt 2>/dev/null || echo "0")

            # Debug: Show raw values
            echo "  Debug: Raw passed_count='$passed_count', Raw failed_count='$failed_count'"

            echo "  Results with exact pattern - Passed: $passed_count, Failed: $failed_count"

            # Try case-insensitive match
            echo "  Trying case-insensitive match..."
            passed_count_ci=$(grep -ci "python ${python_version}" /tmp/test_results/passed.txt 2>/dev/null || echo "0")
            failed_count_ci=$(grep -ci "python ${python_version}" /tmp/test_results/failed.txt 2>/dev/null || echo "0")

            # Debug: Show raw values
            echo "  Debug: Raw passed_count_ci='$passed_count_ci', Raw failed_count_ci='$failed_count_ci'"

            echo "  Results with case-insensitive - Passed: $passed_count_ci, Failed: $failed_count_ci"

            # Try partial match on version only
            echo "  Trying version-only match..."
            passed_count_v=$(grep -c "${python_version}" /tmp/test_results/passed.txt 2>/dev/null || echo "0")
            failed_count_v=$(grep -c "${python_version}" /tmp/test_results/failed.txt 2>/dev/null || echo "0")

            # Debug: Show raw values
            echo "  Debug: Raw passed_count_v='$passed_count_v', Raw failed_count_v='$failed_count_v'"

            echo "  Results with version-only - Passed: $passed_count_v, Failed: $failed_count_v"# Debug: Show the actual matches
            echo "  Sample matches with exact pattern:"
            if grep -q "Python ${python_version}" /tmp/test_results/passed.txt 2>/dev/null; then
              grep "Python ${python_version}" /tmp/test_results/passed.txt 2>/dev/null | head -3
            else
              echo "    No exact matches"
            fi
            echo "  Sample matches with case-insensitive:"
            if grep -qi "python ${python_version}" /tmp/test_results/passed.txt 2>/dev/null; then
              grep -i "python ${python_version}" /tmp/test_results/passed.txt 2>/dev/null | head -3
            else
              echo "    No case-insensitive matches"
            fi
            echo "  Sample matches with version-only:"
            if grep -q "${python_version}" /tmp/test_results/passed.txt 2>/dev/null; then
              grep "${python_version}" /tmp/test_results/passed.txt 2>/dev/null | head -3
            else
              echo "    No version-only matches"
            fi            # Use the best match (prefer exact, then case-insensitive, then version-only)
            if [ "$passed_count" -gt 0 ] || [ "$failed_count" -gt 0 ]; then
              echo "  Using exact pattern results"
              final_passed="${passed_count:-0}"
              final_failed="${failed_count:-0}"
            elif [ "$passed_count_ci" -gt 0 ] || [ "$failed_count_ci" -gt 0 ]; then
              echo "  Using case-insensitive results"
              final_passed="${passed_count_ci:-0}"
              final_failed="${failed_count_ci:-0}"
            else
              echo "  Using version-only results"
              final_passed="${passed_count_v:-0}"
              final_failed="${failed_count_v:-0}"
            fi
            # Ensure variables are numeric (remove any whitespace)
            final_passed=$(echo "$final_passed" | tr -d ' \t\n\r')
            final_failed=$(echo "$final_failed" | tr -d ' \t\n\r')

            # Set defaults if empty
            final_passed="${final_passed:-0}"
            final_failed="${final_failed:-0}"

            # Debug: Show cleaned values before arithmetic
            echo "  Debug: Cleaned final_passed='$final_passed', final_failed='$final_failed'"

            total_count=$((final_passed + final_failed))

            # Calculate success rate for this version
            version_success_rate=0
            if [ $total_count -gt 0 ]; then
              version_success_rate=$(( (final_passed * 100) / total_count ))
            fi

            echo "$total_count,$final_passed,$final_failed,$version_success_rate" > "/tmp/version_stats/python_${python_version}.txt"
            echo "Python $python_version FINAL: Total=$total_count, Passed=$final_passed, Failed=$final_failed, Success=$version_success_rate%"
          done

          # Generate email subject
          if [ $failed_test_cases -eq 0 ]; then
            subject="[APICENTER] Weekly APIC Extension Live Test - All Tests Passed ✅"
          else
            subject="[APICENTER] Weekly APIC Extension Live Test - $failed_test_cases/$total_test_cases Tests Failed ❌"
          fi

          # Calculate overall success rate
          success_rate=0
          if [ $total_test_cases -gt 0 ]; then
            success_rate=$(( (passed_test_cases * 100) / total_test_cases ))
          fi

          # Generate HTML email body with Python version breakdown
          cat > /tmp/email_body.html << 'EOF'
          <html>
          <body>
            <h2>APIC Extension Live Test Report</h2>
            <h3>📊 Overall Summary:</h3>
            <table border="1" cellpadding="5" cellspacing="0" style="border-collapse: collapse;">
              <tr>
                <th>Metric</th>
                <th>Total</th>
                <th>Python 3.9</th>
                <th>Python 3.10</th>
                <th>Python 3.11</th>
                <th>Python 3.12</th>
              </tr>
              <tr>
                <td><strong>Total Test Cases</strong></td>
                <td>TOTAL_PLACEHOLDER</td>
                <td>TOTAL_39_PLACEHOLDER</td>
                <td>TOTAL_310_PLACEHOLDER</td>
                <td>TOTAL_311_PLACEHOLDER</td>
                <td>TOTAL_312_PLACEHOLDER</td>
              </tr>
              <tr>
                <td><strong>Passed</strong></td>
                <td>PASSED_PLACEHOLDER</td>
                <td>PASSED_39_PLACEHOLDER</td>
                <td>PASSED_310_PLACEHOLDER</td>
                <td>PASSED_311_PLACEHOLDER</td>
                <td>PASSED_312_PLACEHOLDER</td>
              </tr>
              <tr>
                <td><strong>Failed</strong></td>
                <td>FAILED_PLACEHOLDER</td>
                <td>FAILED_39_PLACEHOLDER</td>
                <td>FAILED_310_PLACEHOLDER</td>
                <td>FAILED_311_PLACEHOLDER</td>
                <td>FAILED_312_PLACEHOLDER</td>
              </tr>
              <tr>
                <td><strong>Success Rate</strong></td>
                <td>SUCCESS_RATE_PLACEHOLDER%</td>
                <td>SUCCESS_RATE_39_PLACEHOLDER%</td>
                <td>SUCCESS_RATE_310_PLACEHOLDER%</td>
                <td>SUCCESS_RATE_311_PLACEHOLDER%</td>
                <td>SUCCESS_RATE_312_PLACEHOLDER%</td>
              </tr>
            </table>
          EOF

          # Replace overall placeholders
          sed -i "s/TOTAL_PLACEHOLDER/$total_test_cases/g" /tmp/email_body.html
          sed -i "s/PASSED_PLACEHOLDER/$passed_test_cases/g" /tmp/email_body.html
          sed -i "s/FAILED_PLACEHOLDER/$failed_test_cases/g" /tmp/email_body.html
          sed -i "s/SUCCESS_RATE_PLACEHOLDER/$success_rate/g" /tmp/email_body.html

          # Replace per-version placeholders
          for python_version in "${python_versions[@]}"; do
            # Convert version to placeholder format (3.9 -> 39, 3.10 -> 310, etc.)
            version_placeholder=$(echo "$python_version" | sed 's/\.//g')

            if [ -f "/tmp/version_stats/python_${python_version}.txt" ]; then
              IFS=',' read -r total_count passed_count failed_count version_success_rate < "/tmp/version_stats/python_${python_version}.txt"
              echo "Replacing placeholders for Python $python_version: total=$total_count, passed=$passed_count, failed=$failed_count, rate=$version_success_rate%"
            else
              echo "No stats file found for Python $python_version, using zeros"
              total_count=0
              passed_count=0
              failed_count=0
              version_success_rate=0
            fi

            sed -i "s/TOTAL_${version_placeholder}_PLACEHOLDER/$total_count/g" /tmp/email_body.html
            sed -i "s/PASSED_${version_placeholder}_PLACEHOLDER/$passed_count/g" /tmp/email_body.html
            sed -i "s/FAILED_${version_placeholder}_PLACEHOLDER/$failed_count/g" /tmp/email_body.html
            sed -i "s/SUCCESS_RATE_${version_placeholder}_PLACEHOLDER/$version_success_rate/g" /tmp/email_body.html
          done

          # Add failed tests section if any
          if [ $failed_test_cases -gt 0 ] && [ -s /tmp/test_results/failed.txt ]; then
            echo "    <h3>❌ Failed Tests:</h3>" >> /tmp/email_body.html
            echo "    <ul>" >> /tmp/email_body.html
            while IFS= read -r test; do
              if [ -n "$test" ]; then
                echo "      <li>${test}</li>" >> /tmp/email_body.html
              fi
            done < /tmp/test_results/failed.txt
            echo "    </ul>" >> /tmp/email_body.html
          fi

          # Add workflow details
          cat >> /tmp/email_body.html << 'EOF'
            <h3>🔗 Workflow Details:</h3>
            <ul>
              <li><strong>Workflow URL:</strong> <a href="${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}">View Workflow Run</a></li>
              <li><strong>Repository:</strong> ${{ github.repository }}</li>
              <li><strong>Branch:</strong> ${{ github.ref_name }}</li>
              <li><strong>Triggered by:</strong> ${{ github.event_name }}</li>
              <li><strong>Run ID:</strong> ${{ github.run_id }}</li>
              <li><strong>Run Attempt:</strong> ${{ github.run_attempt }}</li>
            </ul>
          </body>
          </html>
          EOF

          # Set environment variables for notification step
          {
            echo "EMAIL_TO=frankqian@microsoft.com"
            echo "EMAIL_SUBJECT<<EOF"
            echo "$subject"
            echo "EOF"
            echo "EMAIL_BODY<<EOF"
            cat /tmp/email_body.html
            echo "EOF"
          } >> $GITHUB_ENV

          # Debug: Show first few lines of email body
          echo "Email body preview (first 10 lines):"
          head -10 /tmp/email_body.html

          # Clean up
          rm -rf /tmp/test_results /tmp/version_stats /tmp/email_body.html /tmp/temp_passed_*.txt /tmp/temp_failed_*.txt

      - name: Send Email Notification
        run: |
          echo "Sending email notification..."

          # Get access token
          response=$(curl -s \
            --request POST \
            --header "Content-Type: application/x-www-form-urlencoded" \
            --data "grant_type=client_credentials&client_id=${{ secrets.MAIL_CLIENT_ID }}&client_secret=${{ secrets.MAIL_CLIENT_SECRET }}&resource=https://management.core.windows.net" \
            "https://login.microsoftonline.com/${{ secrets.MAIL_TENANT_ID }}/oauth2/token")

          access_token=$(echo $response | jq -r '.access_token // empty')

          if [ -z "$access_token" ]; then
            echo "Failed to get access token"
            echo "Response: $response"
            exit 1
          fi

          # Create JSON payload using jq to properly escape special characters
          json_payload=$(jq -n \
            --arg to "$EMAIL_TO" \
            --arg subject "$EMAIL_SUBJECT" \
            --arg body "$EMAIL_BODY" \
            '{to: $to, subject: $subject, body: $body}')

          # Send email
          curl_response=$(curl -s -w "HTTP_STATUS:%{http_code}" \
            --request POST \
            --header "Content-Type: application/json" \
            --header "Authorization: Bearer $access_token" \
            --data "$json_payload" \
            'https://prod-18.northcentralus.logic.azure.com:443/workflows/b33d7861bfc64832a6f62cc8f2213988/triggers/manual/paths/invoke?api-version=2016-10-01&sp=%2Ftriggers%2Fmanual%2Frun&sv=1.0')

          http_status=$(echo "$curl_response" | grep -o "HTTP_STATUS:[0-9]*" | cut -d: -f2)
          response_body=$(echo "$curl_response" | sed 's/HTTP_STATUS:[0-9]*$//')

          echo "Email sending status: $http_status"
          if [ "$http_status" != "200" ] && [ "$http_status" != "202" ]; then
            echo "Failed to send email. Response: $response_body"
            exit 1
          else
            echo "Email sent successfully"
          fi
